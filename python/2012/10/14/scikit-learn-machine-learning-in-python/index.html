<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Scikit Learn: 在Python中机器学习 | Reverland的行知阁</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="python,scikit-learn," />
  

  <meta name="description" content="Scikit Learn: 在python中机器学习Warning
警告：渣翻译，很多我自己都没看懂.但我会慢慢看慢慢修改，此文档维护中……
{:.alert .alert-danger}
翻译自：Scikit Learn:Machine Learning in Python
作者:    Fabian Pedregosa, Gael Varoquaux
先决条件

Numpy, Scipy
IP">
<meta property="og:type" content="article">
<meta property="og:title" content="Scikit Learn: 在Python中机器学习">
<meta property="og:url" content="http://reverland.org/python/2012/10/14/scikit-learn-machine-learning-in-python/index.html">
<meta property="og:site_name" content="Reverland的行知阁">
<meta property="og:description" content="Scikit Learn: 在python中机器学习Warning
警告：渣翻译，很多我自己都没看懂.但我会慢慢看慢慢修改，此文档维护中……
{:.alert .alert-danger}
翻译自：Scikit Learn:Machine Learning in Python
作者:    Fabian Pedregosa, Gael Varoquaux
先决条件

Numpy, Scipy
IP">
<meta property="og:updated_time" content="2015-11-15T06:01:30.267Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Scikit Learn: 在Python中机器学习">
<meta name="twitter:description" content="Scikit Learn: 在python中机器学习Warning
警告：渣翻译，很多我自己都没看懂.但我会慢慢看慢慢修改，此文档维护中……
{:.alert .alert-danger}
翻译自：Scikit Learn:Machine Learning in Python
作者:    Fabian Pedregosa, Gael Varoquaux
先决条件

Numpy, Scipy
IP">

  

  
    <link rel="icon" href="/images/favicon.ico">
  

  

  <link href="/css/styles.css?v=ed12202f" rel="stylesheet">

  

  

</head>

<body>

  
    <a href="#modal-one" class="toolbox-mobile">盒子</a>
  

  <div class="post-header CENTER">
   
  <div class="toolbox">
    <a class="toolbox-entry" href="/">
      <span class="toolbox-entry-text">盒子</span>
      <i class="icon-home"></i>
    </a>
    <ul class="list-toolbox">
      
        <li class="item-toolbox">
          <a 
            class="CIRCLE" 
            href="/archives/"
            target="_self"
            >
            博客
          </a>
        </li>
      
        <li class="item-toolbox">
          <a 
            class="CIRCLE" 
            href="/category/"
            target="_self"
            >
            分类
          </a>
        </li>
      
        <li class="item-toolbox">
          <a 
            class="CIRCLE" 
            href="/tag/"
            target="_self"
            >
            标签
          </a>
        </li>
      
        <li class="item-toolbox">
          <a 
            class="CIRCLE" 
            href="/link/"
            target="_self"
            >
            友链
          </a>
        </li>
      
        <li class="item-toolbox">
          <a 
            class="CIRCLE" 
            href="/about/"
            target="_self"
            >
            关于
          </a>
        </li>
      
        <li class="item-toolbox">
          <a 
            class="CIRCLE" 
            href="/atom.xml"
            target="_blank"
            >
            RSS
          </a>
        </li>
      
    </ul>
  </div>


</div>


  <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Scikit_Learn:_在python中机器学习"><span class="toc-text">Scikit Learn: 在python中机器学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#载入示例数据"><span class="toc-text">载入示例数据</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#一个改变数据集大小的示例：数码数据集(digits_datasets)"><span class="toc-text">一个改变数据集大小的示例：数码数据集(digits datasets)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#学习和预测"><span class="toc-text">学习和预测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#分类"><span class="toc-text">分类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K最近邻(KNN)分类器"><span class="toc-text">K最近邻(KNN)分类器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#训练集和测试集"><span class="toc-text">训练集和测试集</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分类支持向量机(SVMs)"><span class="toc-text">分类支持向量机(SVMs)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#线性支持向量机"><span class="toc-text">线性支持向量机</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#使用核"><span class="toc-text">使用核</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#聚类：将观测值聚合"><span class="toc-text">聚类：将观测值聚合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#k均值聚类"><span class="toc-text">k均值聚类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#应用到图像压缩"><span class="toc-text">应用到图像压缩</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#用主成分分析降维"><span class="toc-text">用主成分分析降维</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#将一切放在一起：人脸识别"><span class="toc-text">将一切放在一起：人脸识别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#线性模型：从回归到稀疏"><span class="toc-text">线性模型：从回归到稀疏</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#稀疏模型"><span class="toc-text">稀疏模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#同一问题的不同算法"><span class="toc-text">同一问题的不同算法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#模型选择：选择估计器和它们的参数"><span class="toc-text">模型选择：选择估计器和它们的参数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#格点搜索和交叉验证估计器"><span class="toc-text">格点搜索和交叉验证估计器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#格点搜索"><span class="toc-text">格点搜索</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#交叉验证估计器"><span class="toc-text">交叉验证估计器</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Footnotes"><span class="toc-text">Footnotes</span></a></li></ol></li></ol>
  </div>



<div class="content content-post CENTER">
   <article id="post-scikit-learn-machine-learning-in-python" class="article article-type-post" itemscope itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">Scikit Learn: 在Python中机器学习</h1>

    <div class="article-meta">
      <span>2012-10-14</span>

      <span> | </span>

      <span class="article-author">Liu Yuyang</span>

      <span> | </span>

      
  <span class="article-category">
    <a class="article-category-link" href="/categories/python/">python</a>
  </span>


    </div>
  </header>

  <div class="article-content">
    
      <h1 id="Scikit_Learn:_在python中机器学习">Scikit Learn: 在python中机器学习</h1><p><div markdown="1"><br><strong><em>Warning</em></strong></div></p>
<p>警告：渣翻译，很多我自己都没看懂.但我会慢慢看慢慢修改，此文档维护中……</p>
<p><br>{:.alert .alert-danger}</p>
<p>翻译自：<a href="http://scipy-lectures.github.com/advanced/scikit-learn/index.html" target="_blank" rel="external">Scikit Learn:Machine Learning in Python</a></p>
<p>作者:    Fabian Pedregosa, Gael Varoquaux</p>
<p><strong>先决条件</strong></p>
<ul>
<li>Numpy, Scipy</li>
<li>IPython</li>
<li>matplotlib</li>
<li><a href="http://scikit-learn.org" target="_blank" rel="external">scikit-learn</a></li>
</ul>
<hr>
<p><strong>目录</strong></p>
<ul>
<li>toc<br>{: toc }</li>
</ul>
<hr>
<blockquote>
<p>警告：在0.9版中(2011年9月发行)，scikit-learn的导入路径从<code>scikits.learn</code>更改为<code>sklearn</code></p>
</blockquote>
<h2 id="载入示例数据">载入示例数据</h2><p>首先我们载入一些用来玩耍的数据。我们将使用的数据是非常简单的著名的花朵数据——安德森鸢尾花卉数据集。</p>
<p>我们有一百五十个鸢尾花的一些尺寸的观测值：萼片长度、宽度，花瓣长度和宽度。还有它们的亚属：山鸢尾（Iris setosa）、变色鸢尾（Iris versicolor）和维吉尼亚鸢尾（Iris virginica）</p>
<p>向python对象载入数据：</p>
<pre><code><span class="type">In</span> [<span class="number">1</span>]: from sklearn <span class="keyword">import</span> datasets
<span class="type">In</span> [<span class="number">2</span>]: iris = datasets.load_iris()
</code></pre><p>数据存储在<code>.data</code>项中，是一个<code>(n_samples, n_features)</code>数组。</p>
<pre><code>In [<span class="number">3</span>]: iris.data.shape
Out[<span class="number">3</span>]: (<span class="number">150</span>, <span class="number">4</span>)
</code></pre><p>每个观察对象的种类存贮在数据集的<code>.target</code>属性中。这是一个长度为<code>n_samples</code>的整数一维数组:</p>
<pre><code>In [<span class="number">5</span>]: iris.target.shape
Out[<span class="number">5</span>]: (<span class="number">150</span>,)

In [<span class="number">6</span>]: import numpy as np

In [<span class="number">7</span>]: np.unique(iris.target)
Out[<span class="number">7</span>]: <span class="built_in">array</span>([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])
</code></pre><h4 id="一个改变数据集大小的示例：数码数据集(digits_datasets)">一个改变数据集大小的示例：数码数据集(digits datasets)</h4><p>数码数据集<a href="[什么手写数字数据集](http://scikit-learn.org/0.11/auto_examples/datasets/plot_digits_last_image.html)">^1</a>包括1797个图像，每一个都是个代表手写数字的8x8像素图像</p>
<pre><code>In [<span class="number">8</span>]: digits = datasets.<span class="function"><span class="title">load_digits</span><span class="params">()</span></span>

In [<span class="number">9</span>]: digits<span class="class">.images</span><span class="class">.shape</span>
Out[<span class="number">9</span>]: (<span class="number">1797</span>, <span class="number">8</span>, <span class="number">8</span>)

In [<span class="number">10</span>]: import pylab as pl

In [<span class="number">11</span>]: pl.<span class="function"><span class="title">imshow</span><span class="params">(digits.images[<span class="number">0</span>], cmap=pl.cm.gray_r)</span></span> 
Out[<span class="number">11</span>]: &lt;matplotlib<span class="class">.image</span><span class="class">.AxesImage</span> at <span class="number">0</span>x3285b90&gt;

In [<span class="number">13</span>]: pl.<span class="function"><span class="title">show</span><span class="params">()</span></span>
</code></pre><p>为了在scikit中使用这个数据集，我们把每个8x8图像转换成长度为64的矢量。(译者注：或者直接用<code>digits.data</code>)</p>
<pre><code><span class="type">In</span> [<span class="number">12</span>]: <span class="type">data</span> = <span class="built_in">digits</span>.images.<span class="built_in">reshape</span>((<span class="built_in">digits</span>.images.<span class="built_in">shape</span>[<span class="number">0</span>], -<span class="number">1</span>))
</code></pre><h3 id="学习和预测">学习和预测</h3><p>现在我们已经获得一些数据，我们想要从中学习和预测一个新的数据。在<code>scikit-learn</code>中，我们通过创建一个<code>估计器(estimator)</code>从已经存在的数据学习，并且调用它的<code>fit(X,Y)</code>方法。</p>
<pre><code><span class="keyword">In</span> [<span class="number">14</span>]: from sklearn import svm

<span class="keyword">In</span> [<span class="number">15</span>]: clf = svm.LinearSVC()

<span class="keyword">In</span> [<span class="number">16</span>]: clf.fit(iris.data, iris.target) # learn from the data 
<span class="keyword">Out</span>[<span class="number">16</span>]: 
LinearSVC(<span class="keyword">C</span>=<span class="number">1.0</span>, class_weight=<span class="keyword">None</span>, dual=<span class="keyword">True</span>, fit_intercept=<span class="keyword">True</span>,
     intercept_scaling=<span class="number">1</span>, loss=<span class="string">'l2'</span>, multi_class=<span class="string">'ovr'</span>, penalty=<span class="string">'l2'</span>,
     tol=<span class="number">0.0001</span>, verbose=<span class="number">0</span>)
</code></pre><p>一旦我们已经从数据学习，我们可以使用我们的模型来预测未观测数据最可能的结果。</p>
<pre><code>In [<span class="number">17</span>]: clf.predict([[ <span class="number">5.0</span>,  <span class="number">3.6</span>,  <span class="number">1.3</span>,  <span class="number">0.25</span>]])
Out[<span class="number">17</span>]: <span class="built_in">array</span>([<span class="number">0</span>], dtype=int32)
</code></pre><p><strong>注意：</strong>我们可以通过它以下划线结束的属性存取模型的参数：</p>
<pre><code>In [<span class="number">18</span>]: clf.coef_  
Out[<span class="number">18</span>]: 
<span class="built_in">array</span>([[ <span class="number">0.18424352</span>,  <span class="number">0.45122644</span>, -<span class="number">0.8079467</span> , -<span class="number">0.45071302</span>],
       [ <span class="number">0.05190619</span>, -<span class="number">0.89423619</span>,  <span class="number">0.40519245</span>, -<span class="number">0.93781587</span>],
       [-<span class="number">0.85087844</span>, -<span class="number">0.98667529</span>,  <span class="number">1.38088883</span>,  <span class="number">1.86538111</span>]])
</code></pre><h2 id="分类">分类</h2><h3 id="K最近邻(KNN)分类器">K最近邻(KNN)分类器</h3><p>最简单的可能的分类器是最近邻：给定一个新的观测值，将n维空间中最靠近它的训练样本标签给它。其中n是每个样本中特性(features)数。</p>
<p>k最近邻<a href="[KNN分类算法](http://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm)">^2</a>分类器内部使用基于球树(ball tree)[^3]来代表它训练的样本。</p>
<p><strong>KNN分类示例</strong>：</p>
<pre><code>In [19]: # <span class="operator"><span class="keyword">Create</span> <span class="keyword">and</span> fit a nearest-neighbor classifier

<span class="keyword">In</span> [<span class="number">20</span>]: <span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors

<span class="keyword">In</span> [<span class="number">21</span>]: knn = neighbors.KNeighborsClassifier()

<span class="keyword">In</span> [<span class="number">22</span>]: knn.fit(iris.<span class="keyword">data</span>, iris.target) 
<span class="keyword">Out</span>[<span class="number">22</span>]: 
KNeighborsClassifier(algorithm=<span class="string">'auto'</span>, leaf_size=<span class="number">30</span>, n_neighbors=<span class="number">5</span>, <span class="keyword">p</span>=<span class="number">2</span>,
           warn_on_equidistant=<span class="literal">True</span>, weights=<span class="string">'uniform'</span>)

<span class="keyword">In</span> [<span class="number">23</span>]: knn.predict([[<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>]])
<span class="keyword">Out</span>[<span class="number">23</span>]: <span class="built_in">array</span>([<span class="number">0</span>])</span>
</code></pre><h4 id="训练集和测试集">训练集和测试集</h4><p>当验证学习算法时，不要用一个用来拟合估计器的数据来验证估计器的预测非常重要。确实，通过kNN估计器，我们将总是获得关于训练集完美的预测。</p>
<pre><code>In [<span class="number">24</span>]: perm = np<span class="class">.random</span><span class="class">.permutation</span>(iris<span class="class">.target</span><span class="class">.size</span>)

In [<span class="number">25</span>]: iris<span class="class">.data</span> = iris<span class="class">.data</span>[perm]

In [<span class="number">26</span>]: iris<span class="class">.target</span> = iris<span class="class">.target</span>[perm]

In [<span class="number">27</span>]: knn.<span class="function"><span class="title">fit</span><span class="params">(iris.data[:<span class="number">100</span>], iris.target[:<span class="number">100</span>])</span></span> 
Out[<span class="number">27</span>]: 
KNeighborsClassifier(algorithm=<span class="string">'auto'</span>, leaf_size=<span class="number">30</span>, n_neighbors=<span class="number">5</span>, p=<span class="number">2</span>,
           warn_on_equidistant=True, weights=<span class="string">'uniform'</span>)

In [<span class="number">28</span>]: knn.<span class="function"><span class="title">score</span><span class="params">(iris.data[<span class="number">100</span>:], iris.target[<span class="number">100</span>:])</span></span> 
/usr/lib/python2.<span class="number">7</span>/site-packages/sklearn/neighbors/classification<span class="class">.py</span>:<span class="number">129</span>: NeighborsWarning: kneighbors: neighbor k+<span class="number">1</span> and neighbor k have the same distance: results will be dependent on data <span class="attribute">order</span>.
  neigh_dist, neigh_ind = self.<span class="function"><span class="title">kneighbors</span><span class="params">(X)</span></span>
Out[<span class="number">28</span>]: <span class="number">0.95999999999999996</span>
</code></pre><p>Bonus的问题：为什么我们使用随机的排列？</p>
<h3 id="分类支持向量机(SVMs)">分类支持向量机(SVMs)</h3><h4 id="线性支持向量机">线性支持向量机</h4><p>SVMs<a href="[支持向量机](http://zh.wikipedia.org/wiki/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA)">^4</a>尝试构建一个两个类别的最大间隔超平面。它选择输入的子集，调用支持向量即离分离的超平面最近的样本点。</p>
<pre><code><span class="keyword">In</span> [<span class="number">60</span>]: from sklearn import svm

<span class="keyword">In</span> [<span class="number">61</span>]: svc = svm.SVC(kernel=<span class="string">'linear'</span>)

<span class="keyword">In</span> [<span class="number">62</span>]: svc.fit(iris.data, iris.target)
<span class="keyword">Out</span>[<span class="number">62</span>]: 
SVC(<span class="keyword">C</span>=<span class="number">1.0</span>, cache_size=<span class="number">200</span>, class_weight=<span class="keyword">None</span>, coef0=<span class="number">0.0</span>, degree=<span class="number">3</span>, gamma=<span class="number">0.0</span>,
  kernel=<span class="string">'linear'</span>, probability=<span class="keyword">False</span>, shrinking=<span class="keyword">True</span>, tol=<span class="number">0.001</span>,
  verbose=<span class="keyword">False</span>)
</code></pre><p><code>scikit-learn</code>中有好几种支持向量机实现。最普遍使用的是<code>svm.SVC</code>，<code>svm.NuSVC</code>和<code>svm.LinearSVC</code>;“SVC”代表支持向量分类器(Support Vector Classifier)(也存在回归SVMs，在<code>scikit-learn</code>中叫作“SVR”)。</p>
<p><strong>练习</strong></p>
<p>训练一个数字数据集的<code>svm.SVC</code>。省略最后10%并且检验观测值的预测表现。</p>
<h4 id="使用核">使用核</h4><p>类别不总是可以用超平面分离，所以人们指望有些可能是多项式或指数实例的非线性决策函数：</p>
<ul>
<li><p>线性核</p>
<pre><code>svc = svm.<span class="function"><span class="title">SVC</span><span class="params">(kernel=<span class="string">'linear'</span>)</span></span>
</code></pre></li>
<li><p>多项式核</p>
<pre><code>svc = svm.SVC(kernel=<span class="string">'poly'</span>,
...               <span class="built_in">degree</span>=<span class="number">3</span>)
<span class="preprocessor"># degree: polynomial degree</span>
</code></pre></li>
<li><p>RBF核(径向基函数)<a href="[径向基函数](http://en.wikipedia.org/wiki/Radial_basis_function)">^5</a></p>
<pre><code>svc = svm.SVC(kernel=<span class="string">'rbf'</span>)
<span class="preprocessor"># gamma: inverse of size of</span>
<span class="preprocessor"># radial kernel</span>
</code></pre></li>
</ul>
<p><strong>练习</strong></p>
<p>以上提到的哪些核对数字数据集有更好的预测性能？(译者：前两个)</p>
<h2 id="聚类：将观测值聚合">聚类：将观测值聚合</h2><p>给定鸢尾花数据集，如果我们知道这有三种鸢尾花，但是无法得到它们的标签，我们可以尝试<em>非监督学习</em>：我们可以通过某些标准<em>聚类</em>观测值到几个组别里。</p>
<h3 id="k均值聚类">k均值聚类</h3><p>最简答的聚类算法是k均值算法。这将一个数据分成k个集群，以最小化观测值(n维空间中)到聚类中心的均值来分配每个观测点到集群;然后均值重新被计算。这个操作递归运行直到聚类收敛，在<code>max_iter</code>回合内到最大值。<a href="[看看wikipedia吧](http://en.wikipedia.org/wiki/K-means_clustering)">^7</a></p>
<p>(一个替代的k均值算法实现在scipy中的<code>cluster</code>包中。这个<code>scikit-learn</code>实现与之不同，通过提供对象API和几个额外的特性，包括智能初始化。)</p>
<pre><code>In [<span class="number">82</span>]: from sklearn import cluster, datasets

In [<span class="number">83</span>]: iris = datasets.<span class="function"><span class="title">load_iris</span><span class="params">()</span></span>

In [<span class="number">84</span>]: k_means = cluster.<span class="function"><span class="title">KMeans</span><span class="params">(k=<span class="number">3</span>)</span></span>

In [<span class="number">85</span>]: k_means.<span class="function"><span class="title">fit</span><span class="params">(iris.data)</span></span> 
Out[<span class="number">85</span>]: 
KMeans(copy_x=True, init=<span class="string">'k-means++'</span>, k=<span class="number">3</span>, max_iter=<span class="number">300</span>, n_init=<span class="number">10</span>, n_jobs=<span class="number">1</span>,
    precompute_distances=True,
    random_state=&lt;mtrand<span class="class">.RandomState</span> <span class="tag">object</span> at <span class="number">0</span>x7f4d860642d0&gt;, tol=<span class="number">0.0001</span>,
    verbose=<span class="number">0</span>)

In [<span class="number">86</span>]: print k_means<span class="class">.labels_</span>[::<span class="number">10</span>]
[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]

In [<span class="number">87</span>]: print iris<span class="class">.target</span>[::<span class="number">10</span>]
[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span>]
</code></pre><h4 id="应用到图像压缩">应用到图像压缩</h4><p>译者注：Lena是经典的图像处理实例图像, 8位灰度色深, 尺寸512 x 512</p>
<p>聚类可以被看作是一种从信息中选择一小部分观测值。例如，这个可以被用来海报化一个图像(将连续变化的色调转换成更少几个色调)：</p>
<pre><code><span class="keyword">In</span> [<span class="number">95</span>]: <span class="keyword">from</span> scipy import misc

<span class="keyword">In</span> [<span class="number">96</span>]: lena = misc.lena().astype(np.float32)

<span class="keyword">In</span> [<span class="number">97</span>]: X = lena.reshape((-<span class="number">1</span>, <span class="number">1</span>)) # We need an (n_sample, n_feature) <span class="keyword">array</span>

<span class="keyword">In</span> [<span class="number">98</span>]: k_means = cluster.KMeans(<span class="number">5</span>)

<span class="keyword">In</span> [<span class="number">99</span>]: k_means.fit(X)
<span class="keyword">Out</span>[<span class="number">99</span>]: 
KMeans(copy_x=<span class="keyword">True</span>, init=<span class="string">'k-means++'</span>, k=<span class="number">5</span>, max_iter=<span class="number">300</span>, n_init=<span class="number">10</span>, n_jobs=<span class="number">1</span>,
    precompute_distances=<span class="keyword">True</span>,
    random_state=&lt;mtrand.RandomState object at <span class="number">0</span>x7f4d860642d0&gt;, tol=<span class="number">0.0001</span>,
    verbose=<span class="number">0</span>)

<span class="keyword">In</span> [<span class="number">100</span>]: values = k_means.cluster_centers_.squeeze()

<span class="keyword">In</span> [<span class="number">101</span>]: labels = k_means.labels_

<span class="keyword">In</span> [<span class="number">102</span>]: lena_compressed = np.choose(labels, values)

<span class="keyword">In</span> [<span class="number">103</span>]: lena_compressed.shape = lena.shape
</code></pre><p>译者注：想看效果？</p>
<pre><code>In [<span class="number">31</span>]: import matplotlib<span class="class">.pyplot</span> as plt

In [<span class="number">32</span>]: plt.<span class="function"><span class="title">gray</span><span class="params">()</span></span>

In [<span class="number">33</span>]: plt.<span class="function"><span class="title">imshow</span><span class="params">(lena_compressed)</span></span>
Out[<span class="number">33</span>]: &lt;matplotlib<span class="class">.image</span><span class="class">.AxesImage</span> at <span class="number">0</span>x4b2c510&gt;

In [<span class="number">34</span>]: plt.<span class="function"><span class="title">show</span><span class="params">()</span></span>
</code></pre><p>原图类似。</p>
<p>![Image]</p>
<h2 id="用主成分分析降维">用主成分分析降维</h2><p>以上根据观测值标记的点云在一个方向非常平坦，所以一个特性几乎可以用其它两个确切地计算。PCA发现哪个方向的数据不是平的并且它可以通过在一个子空间投影来降维。</p>
<p><strong>警告：</strong>PCA将在模块<code>decomposition</code>或<code>pca</code>中，这取决于你scikit-learn的版本。</p>
<pre><code><span class="keyword">In</span> [75]: from sklearn import decomposition

<span class="keyword">In</span> [76]: <span class="keyword">pca</span> = decomposition.<span class="keyword">PCA</span>(n_components=2)

<span class="keyword">In</span> [77]: <span class="keyword">pca</span>.<span class="keyword">fit</span>(iris.data)
<span class="keyword">Out</span>[77]: <span class="keyword">PCA</span>(<span class="keyword">copy</span>=True, n_components=2, whiten=False)

<span class="keyword">In</span> [78]: X = <span class="keyword">pca</span>.transform(iris.data)
</code></pre><p>现在我们可以可视化(降维过的)鸢尾花数据集：</p>
<pre><code><span class="keyword">In</span> [79]: import pylab <span class="keyword">as</span> <span class="keyword">pl</span>

<span class="keyword">In</span> [80]: <span class="keyword">pl</span>.<span class="keyword">scatter</span>(X[:, 0], X[:, 1], c=iris.target)
<span class="keyword">Out</span>[80]: &lt;matplotlib.collections.PathCollection at 0x4104310&gt;
</code></pre><p>PCA不仅在可视化高维数据集时非常有用。它可以用来作为帮助加速对高维数据不那么有效率的监督方法<a href="[监督学习](http://en.wikipedia.org/wiki/Supervised_learning)">^6</a>的预处理步骤。</p>
<h2 id="将一切放在一起：人脸识别">将一切放在一起：人脸识别</h2><p>一个实例使用主成分分析来降维和支持向量机来分类进行人脸识别。</p>
<p>译者注：让程序自动下载(确保联网，文件较大，要等待很久)或者手动下载<a href="http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz" target="_blank" rel="external">数据</a>并放到<code>./scikit_learn_data/lfw_home/</code>下。</p>
<pre><code><span class="string">""</span>"
Stripped-down <span class="keyword">version</span> of the face recognition example <span class="keyword">by</span> Olivier Grisel

http:<span class="comment">//scikit-learn.org/dev/auto_examples/applications/face_recognition.html</span>

## original shape of images: 50, 37
<span class="string">""</span>"
import numpy <span class="keyword">as</span> np
import pylab <span class="keyword">as</span> <span class="keyword">pl</span>
from sklearn import cross_validation, datasets, decomposition, svm

# ..
# .. load data ..
lfw_people = datasets.fetch_lfw_people(min_faces_per_person=70, resize=0.4)
perm = np.random.permutation(lfw_people.target.size)
lfw_people.data = lfw_people.data[perm]
lfw_people.target = lfw_people.target[perm]
faces = np.<span class="keyword">reshape</span>(lfw_people.data, (lfw_people.target.shape[0], -1))
train, <span class="keyword">test</span> = iter(cross_validation.StratifiedKFold(lfw_people.target, k=4)).next()
X_train, X_test = faces[train], faces[<span class="keyword">test</span>]
y_train, y_test = lfw_people.target[train], lfw_people.target[<span class="keyword">test</span>]

# ..
# .. dimension reduction ..
<span class="keyword">pca</span> = decomposition.RandomizedPCA(n_components=150, whiten=True)
<span class="keyword">pca</span>.<span class="keyword">fit</span>(X_train)
X_train_pca = <span class="keyword">pca</span>.transform(X_train)
X_test_pca = <span class="keyword">pca</span>.transform(X_test)

# ..
# .. classification ..
clf = svm.SVC(C=5., <span class="keyword">gamma</span>=0.001)
clf.<span class="keyword">fit</span>(X_train_pca, y_train)

# ..
# .. <span class="keyword">predict</span> <span class="keyword">on</span> new images ..
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="keyword">range</span>(10):
    <span class="keyword">print</span> lfw_people.target_names[clf.<span class="keyword">predict</span>(X_test_pca[i])[0]]
    _ = <span class="keyword">pl</span>.imshow(X_test[i].<span class="keyword">reshape</span>(50, 37), cmap=<span class="keyword">pl</span>.cm.gray)
    _ = raw_input()
</code></pre><p>全部代码：<a href="http://scipy-lectures.github.com/_downloads/faces.py" target="_blank" rel="external">face.py</a></p>
<h2 id="线性模型：从回归到稀疏">线性模型：从回归到稀疏</h2><p><strong>糖尿病数据集</strong></p>
<p>糖尿病数据集包含442个病人的测量而得的10项生理指标(年龄，性别，体重，血压)，和一年后疾病进展的指示：</p>
<pre><code><span class="name">In</span> [<span class="number">104</span>]: <span class="atom">diabetes</span> = <span class="atom">datasets</span>.<span class="atom">load_diabetes</span>()

<span class="name">In</span> [<span class="number">105</span>]: <span class="atom">diabetes_X_train</span> = <span class="atom">diabetes</span>.<span class="atom">data</span>[:-<span class="number">20</span>]

<span class="name">In</span> [<span class="number">106</span>]: <span class="atom">diabetes_X_test</span>  = <span class="atom">diabetes</span>.<span class="atom">data</span>[-<span class="number">20</span>:]

<span class="name">In</span> [<span class="number">107</span>]: <span class="atom">diabetes_y_train</span> = <span class="atom">diabetes</span>.<span class="atom">target</span>[:-<span class="number">20</span>]

<span class="name">In</span> [<span class="number">108</span>]: <span class="atom">diabetes_y_test</span>  = <span class="atom">diabetes</span>.<span class="atom">target</span>[-<span class="number">20</span>:]
</code></pre><p>这个手头的任务是用来从生理指标预测疾病。</p>
<h3 id="稀疏模型">稀疏模型</h3><p>为了改善问题的条件(无信息变量，减少维度的不利影响，作为一个特性(feature)选择的预处理，等等)，我们只关注有信息的特性将没有信息的特性设置为0.这个罚则函数法[^8],叫作<em>套索(Lasso)</em>[^9]，可以将一些系数设置为0.这些方法叫作<em>稀疏方法(sparse method)</em>，稀疏化可以被视作奥卡姆剃刀：相对于复杂模型更倾向于简单的。</p>
<pre><code><span class="keyword">In</span> [<span class="number">109</span>]: <span class="keyword">from</span> sklearn import linear_model

<span class="keyword">In</span> [<span class="number">110</span>]: regr = linear_model.Lasso(alpha=.<span class="number">3</span>)

<span class="keyword">In</span> [<span class="number">111</span>]: regr.fit(diabetes_X_train, diabetes_y_train)
<span class="keyword">Out</span>[<span class="number">111</span>]: 
Lasso(alpha=<span class="number">0.3</span>, copy_X=<span class="keyword">True</span>, fit_intercept=<span class="keyword">True</span>, max_iter=<span class="number">1000</span>,
   normalize=<span class="keyword">False</span>, positive=<span class="keyword">False</span>, precompute=<span class="string">'auto'</span>, tol=<span class="number">0.0001</span>,
   warm_start=<span class="keyword">False</span>)

<span class="keyword">In</span> [<span class="number">112</span>]: regr.coef_ # very sparse coefficients
<span class="keyword">Out</span>[<span class="number">112</span>]: 
<span class="keyword">array</span>([   <span class="number">0</span>.        ,   -<span class="number">0</span>.        ,  <span class="number">497.34075682</span>,  <span class="number">199.17441034</span>,
         -<span class="number">0</span>.        ,   -<span class="number">0</span>.        , -<span class="number">118.89291545</span>,    <span class="number">0</span>.        ,
        <span class="number">430.9379595</span> ,    <span class="number">0</span>.        ])

<span class="keyword">In</span> [<span class="number">113</span>]: regr.score(diabetes_X_test, diabetes_y_test) 
<span class="keyword">Out</span>[<span class="number">113</span>]: <span class="number">0.55108354530029791</span>
</code></pre><p>这个分数和线性回归(最小二乘法)非常相似：</p>
<pre><code>In [<span class="number">114</span>]: lin = linear_model.<span class="function"><span class="title">LinearRegression</span><span class="params">()</span></span>

In [<span class="number">115</span>]: lin.<span class="function"><span class="title">fit</span><span class="params">(diabetes_X_train, diabetes_y_train)</span></span> 
Out[<span class="number">115</span>]: <span class="function"><span class="title">LinearRegression</span><span class="params">(copy_X=True, fit_intercept=True, normalize=False)</span></span>

In [<span class="number">116</span>]: lin.<span class="function"><span class="title">score</span><span class="params">(diabetes_X_test, diabetes_y_test)</span></span> 
Out[<span class="number">116</span>]: <span class="number">0.58507530226905713</span>
</code></pre><h4 id="同一问题的不同算法">同一问题的不同算法</h4><p>同一数学问题可以用不同算法解决。例如,sklearn中的<em>Lasso</em>对象使用坐标下降(coordinate descent)方法[^10]解决套索回归，这在大数据集时非常有效率。然而，sklearn也提供了<em>LassoLARS</em>对象，使用LARS这种在解决权重向量估计非常稀疏，观测值很少的问题很有效率的方法。</p>
<h2 id="模型选择：选择估计器和它们的参数">模型选择：选择估计器和它们的参数</h2><h3 id="格点搜索和交叉验证估计器">格点搜索和交叉验证估计器</h3><h4 id="格点搜索">格点搜索</h4><p>scikit-learn提供了一个对象，该对象给定数据，在拟合一个参数网格的估计器时计算分数，并且选择参数最大化交叉验证分数。这个对象在构建时采用一个估计器并且暴露一个估计器API：</p>
<pre><code><span class="type">In</span> [<span class="number">117</span>]: from sklearn <span class="keyword">import</span> svm, grid_search

<span class="type">In</span> [<span class="number">118</span>]: gammas = np.logspace(-<span class="number">6</span>, -<span class="number">1</span>, <span class="number">10</span>)

<span class="type">In</span> [<span class="number">119</span>]: svc = svm.SVC()

<span class="type">In</span> [<span class="number">120</span>]: clf = grid_search.GridSearchCV(estimator=svc, param_grid=dict(<span class="built_in">gamma</span>=gammas),n_jobs=-<span class="number">1</span>)

<span class="type">In</span> [<span class="number">121</span>]: clf.fit(<span class="built_in">digits</span>.<span class="type">data</span>[:<span class="number">1000</span>], <span class="built_in">digits</span>.<span class="type">target</span>[:<span class="number">1000</span>]) 
<span class="type">Out</span>[<span class="number">121</span>]: 
GridSearchCV(cv=<span class="type">None</span>,
       estimator=SVC(C=<span class="number">1.0</span>, cache_size=<span class="number">200</span>, class_weight=<span class="type">None</span>, coef0=<span class="number">0.0</span>, degree=<span class="number">3</span>, <span class="built_in">gamma</span>=<span class="number">0.0</span>,
  kernel=<span class="string">'rbf'</span>, probability=False, shrinking=True, tol=<span class="number">0.001</span>,
  verbose=False),
       fit_params={}, iid=True, loss_func=<span class="type">None</span>, n_jobs=-<span class="number">1</span>,
       param_grid={<span class="string">'gamma'</span>: array([  <span class="number">1.00000e-06</span>,   <span class="number">3.59381e-06</span>,   <span class="number">1.29155e-05</span>,   <span class="number">4.64159e-05</span>,
         <span class="number">1.66810e-04</span>,   <span class="number">5.99484e-04</span>,   <span class="number">2.15443e-03</span>,   <span class="number">7.74264e-03</span>,
         <span class="number">2.78256e-02</span>,   <span class="number">1.00000e-01</span>])},
       pre_dispatch=<span class="string">'2*n_jobs'</span>, refit=True, score_func=<span class="type">None</span>, verbose=<span class="number">0</span>)

<span class="type">In</span> [<span class="number">122</span>]: clf.best_score
/usr/lib/python2<span class="number">.7</span>/site-packages/sklearn/utils/__init__.py:<span class="number">79</span>: DeprecationWarning: <span class="function"><span class="keyword">Function</span></span> best_score is deprecated; GridSearchCV.best_score is deprecated and will be removed <span class="type">in</span> version <span class="number">0.12.</span> Please <span class="keyword">use</span> ``GridSearchCV.best_score_`` instead.
  warnings.warn(msg, category=DeprecationWarning)
<span class="type">Out</span>[<span class="number">122</span>]: <span class="number">0.98600097103091122</span>

<span class="type">In</span> [<span class="number">123</span>]: clf.best_estimator.<span class="built_in">gamma</span>
/usr/lib/python2<span class="number">.7</span>/site-packages/sklearn/utils/__init__.py:<span class="number">79</span>: DeprecationWarning: <span class="function"><span class="keyword">Function</span></span> best_estimator is deprecated; GridSearchCV.best_estimator is deprecated and will be removed <span class="type">in</span> version <span class="number">0.12.</span> Please <span class="keyword">use</span> ``GridSearchCV.best_estimator_`` instead.
  warnings.warn(msg, category=DeprecationWarning)
<span class="type">Out</span>[<span class="number">123</span>]: <span class="number">0.0021544346900318843</span>
</code></pre><p>默认<code>GridSearchCV</code>使用三次(3-fold)交叉验证。然而，如果它探测到一个分类器被传递，而不是一个回归量，它使用分层的3次。</p>
<h4 id="交叉验证估计器">交叉验证估计器</h4><p>交叉验证在一个algorithm by algorithm基础上可以更有效地设定参数。这就是为何，对给定的估计器，scikit-learn使用“CV”估计器，通过交叉验证自动设定参数。</p>
<pre><code><span class="keyword">In</span> [<span class="number">125</span>]: <span class="keyword">from</span> sklearn import linear_model, datasets

<span class="keyword">In</span> [<span class="number">126</span>]: lasso = linear_model.LassoCV()

<span class="keyword">In</span> [<span class="number">127</span>]: diabetes = datasets.load_diabetes()

<span class="keyword">In</span> [<span class="number">128</span>]: X_diabetes = diabetes.data

<span class="keyword">In</span> [<span class="number">129</span>]: y_diabetes = diabetes.target

<span class="keyword">In</span> [<span class="number">130</span>]: lasso.fit(X_diabetes, y_diabetes)
<span class="keyword">Out</span>[<span class="number">130</span>]: 
LassoCV(alphas=<span class="keyword">array</span>([ <span class="number">2.14804</span>,  <span class="number">2.00327</span>, ...,  <span class="number">0.0023</span> ,  <span class="number">0.00215</span>]),
    copy_X=<span class="keyword">True</span>, cv=None, eps=<span class="number">0.001</span>, fit_intercept=<span class="keyword">True</span>, max_iter=<span class="number">1000</span>,
    n_alphas=<span class="number">100</span>, normalize=<span class="keyword">False</span>, precompute=<span class="string">'auto'</span>, tol=<span class="number">0.0001</span>,
    verbose=<span class="keyword">False</span>)

<span class="keyword">In</span> [<span class="number">131</span>]: # The estimator chose automatically its lambda:

<span class="keyword">In</span> [<span class="number">132</span>]: lasso.alpha 
<span class="keyword">Out</span>[<span class="number">132</span>]: <span class="number">0.013180196198701137</span>
</code></pre><p>这些估计器是相似的，以‘CV’为它们名字的后缀。</p>
<p><strong>练习</strong></p>
<p>对糖尿病数据集，找到最优的正则化参数alpha。(0.016249161908773888)</p>
<hr>
<h2 id="Footnotes">Footnotes</h2><p>[^3]:<a href="http://en.wikipedia.org/wiki/Ball_tree" target="_blank" rel="external">Ball tree数据结构</a></p>
<p>[^8]:<a href="http://en.wikipedia.org/wiki/Penalty_method" target="_blank" rel="external">Penalty methods</a><br>[^9]:<a href="http://en.wikipedia.org/wiki/Least_squares#LASSO_method" target="_blank" rel="external">LASSO method</a><br>[^10]:<a href="http://en.wikipedia.org/wiki/Coordinate_descent" target="_blank" rel="external">Coordinate descent</a></p>

    
  </div>
</article>

</div>


  <a id="backTop" class="back-top">
    <i class="icon-angle-up"></i>
  </a>




  <div class="modal" id="modal-one" aria-hidden="true">
  <a href="#close" class="cover" aria-hidden="true"></a>
  <div class="modal-dialog">
    <div class="modal-header">
      <a href="#close" class="btn-close" aria-hidden="true">关闭</a>
    </div>
    <div class="modal-body">
      <ul class="list-toolbox">
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/archives/"
              target="_self"
              >
              博客
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/category/"
              target="_self"
              >
              分类
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/tag/"
              target="_self"
              >
              标签
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/link/"
              target="_self"
              >
              友链
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/about/"
              target="_self"
              >
              关于
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/atom.xml"
              target="_blank"
              >
              RSS
            </a>
          </li>
        
      </ul>

    </div>
  </div>
</div>



  
      <div class="fexo-comments comments-post">
    
  <section class="disqus-comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>
  </section>

  <script>
    var disqus_shortname = 'reverlandblog';
    
    var disqus_url = 'http://reverland.org/python/2012/10/14/scikit-learn-machine-learning-in-python/';
    
    (function(){
      var dsq = document.createElement('script');
      dsq.type = 'text/javascript';
      dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>


    




  </div>

  

  <script type="text/javascript">
  function loadScript(url, callback) {
    var script = document.createElement('script')
    script.type = 'text/javascript';

    if (script.readyState) { //IE
      script.onreadystatechange = function() {
        if (script.readyState == 'loaded' ||
          script.readyState == 'complete') {
          script.onreadystatechange = null;
          callback();
        }
      };
    } else { //Others
      script.onload = function() {
        callback();
      };
    }

    script.src = url;
    document.getElementsByTagName('head')[0].appendChild(script);
  }

  window.onload = function() {
    loadScript('/js/fastclick.js', function() {
      loadScript('/js/app.js', function() {
        // load success
      });
    });
  }
</script>

</body>
</html>
